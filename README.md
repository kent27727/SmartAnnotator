# ğŸ¯ SmartAnnotator - Auto-Annotation & Training Tool

A comprehensive semi-supervised learning pipeline for object segmentation, detection, and classification. Annotate thousands of images automatically with just 200-300 manual labels!

![Python](https://img.shields.io/badge/Python-3.8+-blue.svg)
![YOLO](https://img.shields.io/badge/YOLO-v11%20%7C%20v8-green.svg)
![License](https://img.shields.io/badge/License-MIT-yellow.svg)

---

## ğŸš€ Quick Start (30 seconds)

```bash
# 1. Clone the repo
git clone https://github.com/yourusername/SmartAnnotator.git
cd SmartAnnotator

# 2. Install dependencies
pip install -r requirements.txt

# 3. Run
python main.py
```

---

## ğŸ“‹ Table of Contents

- [What Does This Tool Do?](#-what-does-this-tool-do)
- [Installation](#-installation)
- [Step-by-Step Guide](#-step-by-step-guide)
- [How Auto-Annotation Works](#-how-auto-annotation-works)
- [FAQ](#-faq)
- [Project Structure](#-project-structure)

---

## ğŸ¤” What Does This Tool Do?

**Problem:** Manually labeling 10,000 images takes days.

**Solution:** 
1. Manually label only **200-300 images**
2. Train an **initial model** with these labels
3. Let the model **automatically annotate** the rest
4. Train the final model with all data

**Result:** Days of work reduced to hours! âš¡

---

## ğŸ”§ Installation

### Requirements
- Python 3.8+
- GPU (recommended, but not required)

### Step 1: Create Environment (Recommended)

```bash
# With Conda
conda create -n annotation python=3.10
conda activate annotation

# Or with venv
python -m venv venv
venv\Scripts\activate  # Windows
source venv/bin/activate  # Linux/Mac
```

### Step 2: Install Dependencies

```bash
pip install -r requirements.txt
```

### Step 3: Run

```bash
python main.py
```

---

## ğŸ“– Step-by-Step Guide

### ğŸ”µ STEP 1: Create a Project

```
python main.py
â†’ Select [1] Project Management
â†’ Select [1] Create New Project
```

You'll be asked:
| Question | Example Answer | Description |
|----------|----------------|-------------|
| Project name | `car_detection` | Name of your project |
| Model | `[1] YOLOv11` | Model to use |
| Task | `[1] Detection` or `[3] Segmentation` | Task type |
| Size | `[3] Medium` | Model size |
| Split | `[1] Automatic` | Train/Val/Test ratios |
| Classes | `car, person` | Classes to detect |
| Min Detections | `1` | Minimum detections per image |

### ğŸ”µ STEP 2: Import Images

```
â†’ Select [2] Import Data
â†’ Select [1] Import raw images
â†’ Enter the path to your image folder
```

Example: `C:\Users\john\Desktop\my_images`

### ğŸ”µ STEP 3: Manual Annotation (200-300 images)

```
â†’ Select [3] Manual Annotation GUI
â†’ Browser opens at http://localhost:7861
```

**How to Use the GUI:**
1. Select your project from the left panel and click **"Load Project"**
2. Click **"Project Images"** to load images
3. **Click on the image** to draw polygon points
4. To complete the polygon, **click on the start point** (white ring)
5. Click **"Save"** or **"Save â†’"** to save and go to next

> ğŸ’¡ **Tip:** Label at least 200-300 images. More = better model!

### ğŸ”µ STEP 4: Train Initial Model

```
â†’ Select [6] Train Initial Model
â†’ Confirm the number of epochs (default: 100)
â†’ Training starts...
```

â±ï¸ **Duration:** 30 minutes - 2 hours depending on GPU

### ğŸ”µ STEP 5: Auto-Annotation â­

```
â†’ Select [4] Start Auto Annotation
â†’ Confirm
â†’ Model automatically labels all images
```

**What happens:**
- âœ… Valid images â†’ `auto_annotations/images/` and `labels/`
- âŒ Invalid images â†’ `auto_annotations/unvalid/`
- ğŸ“Š Statistics are displayed

### ğŸ”µ STEP 6: Prepare Final Dataset

```
â†’ Select [5] Prepare Final Dataset
â†’ Manual + Auto annotations are merged
â†’ Split into Train/Val/Test
```

### ğŸ”µ STEP 7: Train Final Model

```
â†’ Select [7] Train Final Model
â†’ Enter number of epochs (e.g., 150)
â†’ Training starts...
```

ğŸ‰ **Done!** Best model saved at: `projects/PROJECT_NAME/models/`

---

## ğŸ¤– How Auto-Annotation Works

### Workflow

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Trained Model   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Raw Images     â”‚â”€â”€â”€â”€â–¶â”‚  Model Analysis â”‚
â”‚   (1000+ images) â”‚     â”‚                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                  â”‚
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚                           â”‚
                    â–¼                           â–¼
           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
           â”‚   VALID âœ…     â”‚          â”‚  INVALID âŒ    â”‚
           â”‚               â”‚          â”‚               â”‚
           â”‚ â€¢ Min detectionâ”‚          â”‚ â€¢ Few detects â”‚
           â”‚   met          â”‚          â”‚ â€¢ Low confid. â”‚
           â”‚ â€¢ High confid. â”‚          â”‚               â”‚
           â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜          â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
                   â”‚                          â”‚
                   â–¼                          â–¼
           auto_annotations/           auto_annotations/
           â”œâ”€â”€ images/                 â””â”€â”€ unvalid/
           â””â”€â”€ labels/
```

### Minimum Detection Setting

This setting determines **how many objects must be detected** in an image for it to be valid:

| Min Detection | Use Case |
|---------------|----------|
| `1` | Single object detection (car, dog, etc.) |
| `2` | Paired objects (two eyes, etc.) |
| `3+` | Multiple objects required |

**To Change This Setting:**
```
â†’ Select [10] Project Settings
â†’ Select [3] Change annotation settings
â†’ Enter Min Detections value
```

### Confidence Threshold

- **0.5** (default): Medium confidence, more detections
- **0.7**: High confidence, fewer but more accurate detections
- **0.3**: Low confidence, many detections (may be noisy)

---

## â“ FAQ

### "Select a project first!" error
â¡ï¸ First create a project: **[1] Project Management** â†’ **[1] Create New Project**

### How many images should I label?
â¡ï¸ Minimum **200-300 images** recommended. More = better model.

### Does it work without GPU?
â¡ï¸ Yes, but training takes much longer. 100 epochs on CPU = 5-10 hours.

### What does Min Detection do?
â¡ï¸ Sets minimum objects required per image. E.g., `min=2` means images with only 1 detection go to `unvalid/` folder.

### What if auto-labels are wrong?
â¡ï¸ Check `auto_annotations/visualizations/` folder for visual review. Delete incorrect ones.

### Where is the model saved?
â¡ï¸ `projects/PROJECT_NAME/models/latest_model.pt`

### I want to train on a server
â¡ï¸ Use **[8] Server Export (ZIP)** to export all files as a ZIP.

---

## ğŸ“ Project Structure

```
SmartAnnotator/
â”œâ”€â”€ main.py                 # Main menu
â”œâ”€â”€ config.py               # Global settings
â”œâ”€â”€ project_manager.py      # Project management
â”œâ”€â”€ annotation_tool.py      # Manual annotation GUI
â”œâ”€â”€ auto_annotate.py        # Auto annotation engine
â”œâ”€â”€ train_model.py          # Model training
â”œâ”€â”€ prepare_final_dataset.py# Dataset preparation
â”œâ”€â”€ utils.py                # Helper functions
â”œâ”€â”€ requirements.txt        # Python dependencies
â”‚
â””â”€â”€ projects/               # All projects stored here
    â””â”€â”€ my_project/
        â”œâ”€â”€ project_config.json  # Project settings
        â”œâ”€â”€ classes.txt          # Class definitions
        â”œâ”€â”€ raw_images/          # Raw unlabeled images
        â”œâ”€â”€ manual_annotations/  # Manual labels
        â”‚   â”œâ”€â”€ images/
        â”‚   â””â”€â”€ labels/
        â”œâ”€â”€ auto_annotations/    # Auto-generated labels
        â”‚   â”œâ”€â”€ images/          # Valid images
        â”‚   â”œâ”€â”€ labels/          # Label files
        â”‚   â”œâ”€â”€ visualizations/  # Visual previews
        â”‚   â””â”€â”€ unvalid/         # Invalid images
        â”œâ”€â”€ final_dataset/       # Ready for training
        â”‚   â”œâ”€â”€ train/
        â”‚   â”œâ”€â”€ val/
        â”‚   â”œâ”€â”€ test/
        â”‚   â””â”€â”€ dataset.yaml
        â””â”€â”€ models/              # Trained models
            â””â”€â”€ latest_model.pt
```

---

## âš™ï¸ Project Configuration (project_config.json)

```json
{
  "project_name": "car_detection",
  "model": {
    "family": "yolov11",
    "task": "detection",
    "size": "m",
    "weights": "yolo11m.pt"
  },
  "classes": {
    "0": "car",
    "1": "person"
  },
  "split": "auto",
  "training": {
    "epochs": 100,
    "batch_size": 16,
    "image_size": 640
  },
  "annotation": {
    "confidence_threshold": 0.5,
    "iou_threshold": 0.45,
    "min_detections": 1
  }
}
```

---

## ğŸ·ï¸ Label Formats

### YOLO Segmentation Format
```
# class_id x1 y1 x2 y2 x3 y3 ... (normalized 0-1)
0 0.234 0.456 0.345 0.567 0.456 0.678 ...
```

### YOLO Detection Format
```
# class_id x_center y_center width height (normalized 0-1)
0 0.5 0.5 0.2 0.3
```

---

## ğŸ“Š Model Sizes

| Size | Name | Speed | Accuracy | Use Case |
|------|------|-------|----------|----------|
| `n` | Nano | âš¡âš¡âš¡âš¡âš¡ | â­ | Mobile/Edge |
| `s` | Small | âš¡âš¡âš¡âš¡ | â­â­ | Fast inference |
| `m` | Medium | âš¡âš¡âš¡ | â­â­â­ | Balanced (recommended) |
| `l` | Large | âš¡âš¡ | â­â­â­â­ | High accuracy |
| `x` | XLarge | âš¡ | â­â­â­â­â­ | Maximum accuracy |

---

## ğŸ¤ Contributing

1. Fork the repo
2. Create feature branch (`git checkout -b feature/NewFeature`)
3. Commit changes (`git commit -m 'Add new feature'`)
4. Push (`git push origin feature/NewFeature`)
5. Open Pull Request

---

## ğŸ“„ License

MIT License - See [LICENSE](LICENSE) for details.

---

## ğŸ™ Acknowledgments

- [Ultralytics](https://github.com/ultralytics/ultralytics) - YOLO implementation
- [Gradio](https://gradio.app/) - GUI framework
- [OpenCV](https://opencv.org/) - Image processing

---

**Made with â¤ï¸ for the computer vision community**
